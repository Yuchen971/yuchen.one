alias:: 归一化, scale, standardization, normalization, 中心化

- 归一化 (normalization)
	- rescaling (min-max normalization, range scaling)
		- $$
		  X_{new}=a+\frac{(x-\min (x))(b-a)}{\max (x)-\min (x)}
		  $$
			- 将每一维特征线性映射到目标范围[a,b]
		- $$
		  X_{n e w}=\frac{X_{i}-X_{\min }}{X_{\max }-X_{\min }},  \in [0,1]
		  $$
	- Mean normalization
		- $$
		  X_{n e w}=\frac{X_{i}-\operatorname{mean}(X)}{X_{\max }-X_{\min }} \in [-1,1]
		  $$
	- 输出范围在固定的值之间, 比如 [0,1], [0,255], [-1,1]
	- 如果对输出结果范围有要求, 用归一化
	- 如果数据较为稳定, 不存在极端的最大最小值, 用归一化
- 标准化 (standardization)
	- z-score normalization
		- $$
		  X_{n e w}=\frac{X_{i}-\mu}{\sigma}
		  $$
	- 输出范围是负无穷到正无穷, ==mean = 0, sd = 1== 的分布, 不一定是正态
	- 如果数据存在异常值和较多噪音, 用标准化可以间接通过中心化避免异常值和极端值的影响
- 中心化
	- 也叫零均值处理, 就是原始数据减去这些数据的均值 mean = 0
- Note
	- 统计建模的时候, 如果自变量X的量纲不一样, 导致回归系数无法直接解读或者错误解读, 需要把X处理到同意量纲下, 这样才可比
	- ==用到距离的模型, 不同维度量纲不同导致距离的计算依赖于量纲大的那些特征从而得到不合理的结果==
	- 参数估计时使用 [[梯度下降]] 求解最优化问题的时候, 归一化或者标准化可以加快梯度下降的求解速度, 提升模型的收敛速度
- 标准化, 归一化 [[CheatSheet/Python]]
	- 缩放到均值为0, 方差为1 (Standardization——`StandardScaler()`) (z-score归一化)
	- 缩放到0和1之间 (Standardization——`MinMaxScaler()`) (min-max归一化)
	- 缩放到-1和1之间 (Standardization——`MaxAbsScaler()`)
	- 缩放到0和1之间, 保留原始数据的分布 (Normalization——`Normalizer()`)
- 标准化, 归一化 [[CheatSheet/R]]
	- ```r
	  scale(dt, center = T, scale = T)
	  # center为真表示数据中心化(只减去均值不做其他处理)
	  # scale为真表示数据标准化 mean = 0, sd = 1
	  ```